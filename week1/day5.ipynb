{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98030af-fcd1-4d63-a36e-38ba053498fa",
   "metadata": {},
   "source": [
    "# A full business solution\n",
    "\n",
    "## Now we will take our project from Day 1 to the next level\n",
    "\n",
    "### BUSINESS CHALLENGE:\n",
    "\n",
    "Create a product that builds a Brochure for a company to be used for prospective clients, investors and potential recruits.\n",
    "\n",
    "We will be provided a company name and their primary website.\n",
    "\n",
    "See the end of this notebook for examples of real-world business applications.\n",
    "\n",
    "And remember: I'm always available if you have problems or ideas! Please do reach out."
   ]
  },
  {
   "cell_type": "code",
   "id": "d5b08506-dc8b-4443-9201-5f1848161363",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:21:26.393128Z",
     "start_time": "2025-01-27T08:21:25.305974Z"
    }
   },
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "fc5d8880-f2ee-4c06-af16-ecbc0262af61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:21:36.021349Z",
     "start_time": "2025-01-27T08:21:35.917961Z"
    }
   },
   "source": [
    "# Initialize and constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "106dd65e-90af-4ca8-86b6-23a41840645b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:21:47.992347Z",
     "start_time": "2025-01-27T08:21:47.986939Z"
    }
   },
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with links\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "e30d8128-933b-44cc-81c8-ab4c9d86589a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:22:18.207870Z",
     "start_time": "2025-01-27T08:22:18.141073Z"
    }
   },
   "source": [
    "ed = Website(\"https://urszulaczerwinska.github.io/\")\n",
    "ed.links"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/index.html',\n",
       " '#menu',\n",
       " '/index.html',\n",
       " '/about/',\n",
       " '/works/',\n",
       " '/thoughts/',\n",
       " '/feed.xml',\n",
       " '#greeting',\n",
       " 'https://twitter.com/ulalaparis',\n",
       " 'https://github.com/urszulaczerwinska',\n",
       " 'https://linkedin.com/in/urszulaczerwinska',\n",
       " '/thoughts/',\n",
       " '/thoughts/',\n",
       " '/works/',\n",
       " '/works/',\n",
       " '/works/deep-dive-in-paddleocr-inference',\n",
       " '/works/ner_cc',\n",
       " '/works/interpretability-shap',\n",
       " '/works/egg_ner',\n",
       " 'https://twitter.com/ulalaparis',\n",
       " 'https://github.com/urszulaczerwinska',\n",
       " 'https://linkedin.com/in/urszulaczerwinska',\n",
       " 'mailto:ulcia.liberte@gmail.com',\n",
       " '/credits/']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "1771af9c-717a-4fca-bbbe-8a95893312c3",
   "metadata": {},
   "source": [
    "## First step: Have GPT-4o-mini figure out which links are relevant\n",
    "\n",
    "### Use a call to gpt-4o-mini to read the links on a webpage, and respond in structured JSON.  \n",
    "It should decide which links are relevant, and replace relative links such as \"/about\" with \"https://company.com/about\".  \n",
    "We will use \"one shot prompting\" in which we provide an example of how it should respond in the prompt.\n",
    "\n",
    "This is an excellent use case for an LLM, because it requires nuanced understanding. Imagine trying to code this without LLMs by parsing and analyzing the webpage - it would be very hard!\n",
    "\n",
    "Sidenote: there is a more advanced technique called \"Structured Outputs\" in which we require the model to respond according to a spec. We cover this technique in Week 8 during our autonomous Agentic AI project."
   ]
  },
  {
   "cell_type": "code",
   "id": "6957b079-0d96-45f7-a26a-3487510e9b35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:22:40.090422Z",
     "start_time": "2025-01-27T08:22:40.085534Z"
    }
   },
   "source": [
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "b97e4068-97ed-4120-beae-c42105e4d59a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:22:52.310890Z",
     "start_time": "2025-01-27T08:22:52.306252Z"
    }
   },
   "source": [
    "print(link_system_prompt)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are provided with a list of links found on a webpage. You are able to decide which of the links would be most relevant to include in a brochure about the company, such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
      "You should respond in JSON as in this example:\n",
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
      "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
      "    ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "8e1f601b-2eaf-499d-b6b8-c99050c9d6b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:22:56.609218Z",
     "start_time": "2025-01-27T08:22:56.605946Z"
    }
   },
   "source": [
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "6bcbfa78-6395-4685-b92c-22d592050fd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:22:59.483860Z",
     "start_time": "2025-01-27T08:22:59.474258Z"
    }
   },
   "source": [
    "print(get_links_user_prompt(ed))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the list of links on the website of https://urszulaczerwinska.github.io/ - please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. Do not include Terms of Service, Privacy, email links.\n",
      "Links (some might be relative links):\n",
      "/index.html\n",
      "#menu\n",
      "/index.html\n",
      "/about/\n",
      "/works/\n",
      "/thoughts/\n",
      "/feed.xml\n",
      "#greeting\n",
      "https://twitter.com/ulalaparis\n",
      "https://github.com/urszulaczerwinska\n",
      "https://linkedin.com/in/urszulaczerwinska\n",
      "/thoughts/\n",
      "/thoughts/\n",
      "/works/\n",
      "/works/\n",
      "/works/deep-dive-in-paddleocr-inference\n",
      "/works/ner_cc\n",
      "/works/interpretability-shap\n",
      "/works/egg_ner\n",
      "https://twitter.com/ulalaparis\n",
      "https://github.com/urszulaczerwinska\n",
      "https://linkedin.com/in/urszulaczerwinska\n",
      "mailto:ulcia.liberte@gmail.com\n",
      "/credits/\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "a29aca19-ca13-471c-a4b4-5abbfa813f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:23:05.259770Z",
     "start_time": "2025-01-27T08:23:05.254004Z"
    }
   },
   "source": [
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "      ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return json.loads(result)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "74a827a0-2782-4ae5-b210-4a242a8b4cc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:23:06.321167Z",
     "start_time": "2025-01-27T08:23:06.245924Z"
    }
   },
   "source": [
    "# Anthropic has made their site harder to scrape, so I'm using HuggingFace..\n",
    "\n",
    "huggingface = Website(\"https://huggingface.co\")\n",
    "huggingface.links"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/posts',\n",
       " '/docs',\n",
       " '/enterprise',\n",
       " '/pricing',\n",
       " '/login',\n",
       " '/join',\n",
       " '/deepseek-ai/DeepSeek-R1',\n",
       " '/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B',\n",
       " '/deepseek-ai/DeepSeek-R1-Zero',\n",
       " '/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B',\n",
       " '/hexgrad/Kokoro-82M',\n",
       " '/models',\n",
       " '/spaces/tencent/Hunyuan3D-2',\n",
       " '/spaces/hexgrad/Kokoro-TTS',\n",
       " '/spaces/webml-community/deepseek-r1-webgpu',\n",
       " '/spaces/lllyasviel/iclight-v2',\n",
       " '/spaces/JeffreyXiang/TRELLIS',\n",
       " '/spaces',\n",
       " '/datasets/fka/awesome-chatgpt-prompts',\n",
       " '/datasets/cais/hle',\n",
       " '/datasets/bespokelabs/Bespoke-Stratos-17k',\n",
       " '/datasets/HumanLLMs/Human-Like-DPO-Dataset',\n",
       " '/datasets/yale-nlp/MMVU',\n",
       " '/datasets',\n",
       " '/join',\n",
       " '/pricing#endpoints',\n",
       " '/pricing#spaces',\n",
       " '/pricing',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/allenai',\n",
       " '/facebook',\n",
       " '/amazon',\n",
       " '/google',\n",
       " '/Intel',\n",
       " '/microsoft',\n",
       " '/grammarly',\n",
       " '/Writer',\n",
       " '/docs/transformers',\n",
       " '/docs/diffusers',\n",
       " '/docs/safetensors',\n",
       " '/docs/huggingface_hub',\n",
       " '/docs/tokenizers',\n",
       " '/docs/peft',\n",
       " '/docs/transformers.js',\n",
       " '/docs/timm',\n",
       " '/docs/trl',\n",
       " '/docs/datasets',\n",
       " '/docs/text-generation-inference',\n",
       " '/docs/accelerate',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/tasks',\n",
       " 'https://ui.endpoints.huggingface.co',\n",
       " '/chat',\n",
       " '/huggingface',\n",
       " '/brand',\n",
       " '/terms-of-service',\n",
       " '/privacy',\n",
       " 'https://apply.workable.com/huggingface/',\n",
       " 'mailto:press@huggingface.co',\n",
       " '/learn',\n",
       " '/docs',\n",
       " '/blog',\n",
       " 'https://discuss.huggingface.co',\n",
       " 'https://status.huggingface.co/',\n",
       " 'https://github.com/huggingface',\n",
       " 'https://twitter.com/huggingface',\n",
       " 'https://www.linkedin.com/company/huggingface/',\n",
       " '/join/discord']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "d3d583e2-dcc4-40cc-9b28-1e8dbf402924",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:23:16.624364Z",
     "start_time": "2025-01-27T08:23:12.494773Z"
    }
   },
   "source": [
    "get_links(\"https://huggingface.co\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'about page', 'url': 'https://huggingface.co/huggingface'},\n",
       "  {'type': 'careers page', 'url': 'https://apply.workable.com/huggingface/'},\n",
       "  {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'},\n",
       "  {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'},\n",
       "  {'type': 'blog page', 'url': 'https://huggingface.co/blog'},\n",
       "  {'type': 'community discussion page',\n",
       "   'url': 'https://discuss.huggingface.co'},\n",
       "  {'type': 'GitHub page', 'url': 'https://github.com/huggingface'},\n",
       "  {'type': 'LinkedIn page',\n",
       "   'url': 'https://www.linkedin.com/company/huggingface/'},\n",
       "  {'type': 'Twitter page', 'url': 'https://twitter.com/huggingface'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "0d74128e-dfb6-47ec-9549-288b621c838c",
   "metadata": {},
   "source": [
    "## Second step: make the brochure!\n",
    "\n",
    "Assemble all the details into another prompt to GPT4-o"
   ]
  },
  {
   "cell_type": "code",
   "id": "85a5b6e2-e7ef-44a9-bc7f-59ede71037b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:23:22.113956Z",
     "start_time": "2025-01-27T08:23:22.110865Z"
    }
   },
   "source": [
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = get_links(url)\n",
    "    print(\"Found links:\", links)\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()\n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "5099bd14-076d-4745-baf3-dac08d8e5ab2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:23:31.227286Z",
     "start_time": "2025-01-27T08:23:29.064571Z"
    }
   },
   "source": "print(get_all_details(\"https://urszulaczerwinska.github.io/\"))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://urszulaczerwinska.github.io/about/'}, {'type': 'works page', 'url': 'https://urszulaczerwinska.github.io/works/'}, {'type': 'careers page', 'url': 'https://urszulaczerwinska.github.io/thoughts/'}]}\n",
      "Landing page:\n",
      "Webpage Title:\n",
      "Urszula Czerwinska | Python, TensorFlow Expert | Data Scientist & Deep Learning Engineer\n",
      "Webpage Contents:\n",
      "Urszula Czerwinska\n",
      "Menu\n",
      "Home\n",
      "About\n",
      "Works\n",
      "Thoughts\n",
      "RSS Feed\n",
      "Urszula Czerwinska\n",
      "Science → Data Science\n",
      "Continue\n",
      "Welcome to My Data Science Journey\n",
      "Welcome to my personal blog, where I documented my transition from a PhD in Computational Biology to a thriving career in Data Science. Here, you’ll find insights on where to learn data science, how data science and machine learning, artificial intelligence are revolutionizing various fields, and explore whether data science can be self-taught, are data science bootcamps or courses worth it. Discover why data science is important in today’s world.\n",
      "twitter\n",
      "github\n",
      "linkedin-square\n",
      "Thoughts\n",
      "Welcome to my Thoughts page, where I explore the dynamic intersections of my professional journey. Here, I share reflections on attending conferences, maintaining work-life balance, and the challenging transition from academia to industry. You’ll also find my evaluations of Data Science bootcamps and courses, along with insights into the latest state-of-the-art (SOTA) deep learning trends. Drawing from my PhD experience and ongoing career, these articles offer a candid look at the evolving landscape of data science and the realities of working at the cutting edge of technology.\n",
      "Works\n",
      "Welcome to my Works portfolio. Here, you'll find my PhD research on cancer computational biology, focusing on dimension reduction with ICA, alongside my NLP and model explainability (SHAP) projects from my consulting experience. Also featured are the NLP (NER), Deep Learning projects I completed at the French Supreme Court, and my recent work in Computer Vision and Generative AI. This portfolio reflects my ability to solve complex challenges and drive innovation across diverse fields and application of Deep Learning algorithms in industry.\n",
      "Recent posts\n",
      "Explore my latest highlights, featuring standout projects and insights on the transition from academia to industry & life of Data Scientist / Deep learning engineer. Whether it’s hands-on work or reflections from the field, these featured posts capture the key moments of my data science journey.\n",
      "Deep Dive in PaddleOCR inference\n",
      "Discover the complexities of using PaddleOCR as a Text in Image service and how the Cognition...\n",
      "Named Entity Recognition Tool by Cour de Cassation\n",
      "Description of pseudonymisation for Open Data of French Supreme Court decisions\n",
      "Push the limits of machine learning explainability\n",
      "an ultimate guide to SHAP library\n",
      "Mastering Named Entity Recognition (NER) in Data Science\n",
      "Extracting Keywords from Medium Articles Using SpaCy\n",
      "Thanks for visiting, dear Data Science Lover !\n",
      "Feel free to get in touch and talk about how deep learning can help your business or solve your problem. Let's connect!\n",
      "twitter\n",
      "github\n",
      "linkedin-square\n",
      "E-mail\n",
      "© 2016,\n",
      "    2024\n",
      "      Urszula Czerwinska\n",
      "Credits\n",
      "\n",
      "\n",
      "\n",
      "about page\n",
      "Webpage Title:\n",
      "About\n",
      "Webpage Contents:\n",
      "Urszula Czerwinska\n",
      "Menu\n",
      "Home\n",
      "About\n",
      "Works\n",
      "Thoughts\n",
      "RSS Feed\n",
      "About\n",
      "Expert Deep Learning Engineer in Paris | AI, Data Science, and Industry Solutions\n",
      "Home\n",
      "About\n",
      "Urszula Czerwinska\n",
      "Senior Deep Learning engineer, Data Scientist, PhD\n",
      "urszula.czerwinska@cri-paris.org\n",
      "|\n",
      "urszulaczerwinska\n",
      "|\n",
      "ulalaparis\n",
      "|\n",
      "Urszula Czerwinska\n",
      "          |\n",
      "UlaLaParis\n",
      "Download CV\n",
      "Short Bio\n",
      "Born in Poland and having gained diverse educational experiences\n",
      "        across France and Singapore,\n",
      "        I now proudly call Paris home. My journey, rooted in\n",
      "bio-mathematics\n",
      ",\n",
      "        culminating in a\n",
      "Ph.D.\n",
      ",\n",
      "        has equipped me with profound expertise in\n",
      "complex\n",
      "          systems\n",
      ",\n",
      "statistics\n",
      ", and\n",
      "programming\n",
      ",\n",
      "        particularly in\n",
      "Python\n",
      "and\n",
      "R\n",
      ". These interdisciplinary\n",
      "        experiences\n",
      "        have sharpened my ability to excel in bridging the gap between\n",
      "        theoretical knowledge\n",
      "        and practical application, specially in the realms of\n",
      "deep\n",
      "          learning\n",
      "and\n",
      "data science\n",
      ".\n",
      "As a\n",
      "Senior Deep Learning Engineer - Data Scientist\n",
      "at\n",
      "Adevinta\n",
      "in Paris, my current\n",
      "        focus is\n",
      "        on spearheading advancements in\n",
      "computer vision\n",
      "and\n",
      "multimodal AI models\n",
      ". I lead the strategic development\n",
      "        of\n",
      "foundation models\n",
      "that drive product innovation and\n",
      "        enhance\n",
      "e-commerce solutions\n",
      ". My work leverages\n",
      "        cutting-edge technologies like\n",
      "PyTorch\n",
      ",\n",
      "TensorFlow\n",
      ", and\n",
      "Kubernetes\n",
      ", where I guide my team to deliver\n",
      "        exceptional results.\n",
      "        Notably, I’ve improved\n",
      "scene-text extraction\n",
      "capabilities by\n",
      "33%\n",
      "and optimized multi-class classification models to\n",
      "        increase\n",
      "        accuracy by\n",
      "45%\n",
      ".\n",
      "My role at Adevinta also encompasses leadership beyond technical\n",
      "        accomplishments.\n",
      "        As the head of the\n",
      "Adevinta ML Guild\n",
      ", I facilitate paper reading sessions\n",
      "        and am actively involved in recruiting a Ph.D.\n",
      "        expert to further strengthen our team. This position allows me to\n",
      "        nurture a\n",
      "culture of continuous learning and\n",
      "          innovation\n",
      ", a pursuit I am deeply passionate about.\n",
      "Before my role at Adevinta, I served as a\n",
      "Senior Data\n",
      "        Scientist and NLP\n",
      "        Engineer\n",
      "at the\n",
      "French Supreme Court\n",
      ", where I\n",
      "        developed\n",
      "language models\n",
      "and\n",
      "named entity\n",
      "          recognition systems\n",
      ". These innovations automated the\n",
      "          anonymization of\n",
      "          judicial documents, boosting productivity by\n",
      "45%\n",
      ". My\n",
      "          role required close collaboration with\n",
      "academia\n",
      ",\n",
      "public institutions\n",
      ", and the\n",
      "European\n",
      "            Commission\n",
      "was a\n",
      "          significant part of this role, underscoring my ability to integrate\n",
      "          research\n",
      "          with practical solutions.\n",
      "I am also an advocate for\n",
      "diversity in tech\n",
      ".\n",
      "        My previous role as an ambassador for the\n",
      "Pivigo Data\n",
      "            Science hub\n",
      "and my involvement with the\n",
      "Women\n",
      "          in Healthcare and Data\n",
      "          Science\n",
      "Paris meetup, where I organized events bridging\n",
      "        academia and industry, reflect this commitment.\n",
      "In addition to my professional roles, I’ve contributed a chapter on\n",
      "ML model\n",
      "          interpretability\n",
      "to\n",
      "Applied Data Science in Tourism\n",
      "a Data Science book and\n",
      "        have shared my work at various international conferences and through\n",
      "        publications.\n",
      "I’m driven by the opportunity to build impactful\n",
      "AI\n",
      "          models\n",
      "that\n",
      "solve real-world problems\n",
      ", foster a culture of\n",
      "        continuous learning, and\n",
      "        promote the responsible use of AI. You can bump into me while attending\n",
      "        some of AI, Deep Learning\n",
      "        conferences such as ICCV, ECC, ICR or NeurIPS. Let’s connect to explore\n",
      "        how we can collaborate to drive innovation\n",
      "        and harness the power of AI to achieve transformative results.\n",
      "Skills\n",
      "Deep Learning\n",
      "Computer Vision\n",
      "NLP\n",
      "Diffusion Models\n",
      "LLMs\n",
      "Statistics\n",
      "Python\n",
      "Biology & Healthcare related expertise\n",
      "Communication\n",
      "Professional experience\n",
      "I have been developing diverse projects in\n",
      "Computer\n",
      "          Vision\n",
      ",\n",
      "NLP\n",
      ",\n",
      "Data Science\n",
      ",\n",
      "bioinformatics\n",
      ", biology and others. Have a look at my\n",
      "Works\n",
      ".\n",
      "Education\n",
      "2015-2018\n",
      "Institut Curie\n",
      "Ph.D.\n",
      "in Computational Biology\n",
      "Courses & certificates\n",
      "2024\n",
      "Hugging Face Diffusion Models\n",
      "                      Course\n",
      "hands-on course on diffusion models, stable diffusion with\n",
      "                  diffusers library\n",
      "2024\n",
      "TensorFlow Developer\n",
      "                      Certificate\n",
      "Certified through external exam by Google on deeplearnig\n",
      "                  library Tensorflow\n",
      "2024\n",
      "Emerge Her Adevinta\n",
      "Internal program of 4 months strengthening woman leadership\n",
      "                skills, personal coaching, Clifton Strength workshop\n",
      "2024\n",
      "Generative AI with Large Language\n",
      "                    Models\n",
      "Deeplearing.ai and Coursera certificate for learning\n",
      "                fundamentals of LLMs and GenAI\n",
      "2020\n",
      "CS224n:\n",
      "                    Natural Language Processing with\n",
      "                    Deep Learning\n",
      "Stanford online course, completed as autodidact, not\n",
      "                certifying\n",
      "2017\n",
      "Data\n",
      "                    Science Summer School\n",
      "Ecole Polytechnique: Deep Learning, Graphical Models,\n",
      "                Optimisation\n",
      "2017\n",
      "BIG DIVE\n",
      "5-week intense big data & data visualization hands-on course,\n",
      "                final project for\n",
      "International Finance Corporation\n",
      "2017\n",
      "Python hacking week\n",
      "HackInScience\n",
      "2017\n",
      "Build and manage your professional network\n",
      "Sorbonne Paris Cité\n",
      "2017\n",
      "Distruptive technologies and public policy\n",
      "SciencesPo certified course, final grade: 17.5/20\n",
      "2016\n",
      "CBA : certificate of Business and\n",
      "                  Administration\n",
      "Sorbonne Paris Cité & Adoc Management\n",
      "2016\n",
      "Analytics Edge\n",
      "EdX honor code\n",
      "2016\n",
      "Data Science Essentials by Microsoft\n",
      "EdX certified honor code\n",
      "2016\n",
      "Machine Learning\n",
      "Stanford University online course\n",
      "2015\n",
      "Marketing and Business Strategies\n",
      "Smart Albinos online course\n",
      "2015\n",
      "Elevator pitch\n",
      "Speak the speech consulting\n",
      "Languages\n",
      "English\n",
      "French\n",
      "Spanish\n",
      "Russian\n",
      "Polish\n",
      "Academic\n",
      "For\n",
      "publications\n",
      "see\n",
      "my orcid profile\n",
      ",\n",
      "        for\n",
      "posters\n",
      ",\n",
      "science awards\n",
      "and\n",
      "talks\n",
      "please see my\n",
      "academic CV\n",
      ".\n",
      "Intrests\n",
      "Travels\n",
      "Foreign languages\n",
      "Leadership\n",
      "Boxing\n",
      "Cycling\n",
      "Motorcycling\n",
      "twitter\n",
      "github\n",
      "linkedin-square\n",
      "E-mail\n",
      "© 2016,\n",
      "    2024\n",
      "      Urszula Czerwinska\n",
      "Credits\n",
      "\n",
      "\n",
      "\n",
      "works page\n",
      "Webpage Title:\n",
      "Works\n",
      "Webpage Contents:\n",
      "Urszula Czerwinska\n",
      "Menu\n",
      "Home\n",
      "About\n",
      "Works\n",
      "Thoughts\n",
      "RSS Feed\n",
      "Works\n",
      "The portfolio — overview of projects\n",
      "Home\n",
      "Works\n",
      "Visit my\n",
      "LinkedIn\n",
      "and\n",
      "Github\n",
      "profiles for more great works on ML and Deep Learning !\n",
      "Text in Image 2.0 - improving OCR service with PaddleOCR\n",
      "Mar 2023\n",
      "Read how the Cognition team improved the Text in Image service across...\n",
      "data science\n",
      "OCR\n",
      "deep learning\n",
      "computer vision\n",
      "machine learning\n",
      "API\n",
      "Deep Dive in PaddleOCR inference\n",
      "Mar 2023\n",
      "Discover the complexities of using PaddleOCR as a Text in Image service...\n",
      "data science\n",
      "OCR\n",
      "deep learning\n",
      "computer vision\n",
      "machine learning\n",
      "Named Entity Recognition Tool by Cour de Cassation\n",
      "Sep 2021\n",
      "Description of pseudonymisation for Open Data of French Supreme Court decisions\n",
      "Machine Learning\n",
      "Python\n",
      "Deep Learning\n",
      "NER\n",
      "NLP\n",
      "Justice\n",
      "Flair\n",
      "Push the limits of machine learning explainability\n",
      "Mar 2020\n",
      "an ultimate guide to SHAP library\n",
      "data science\n",
      "interpretability\n",
      "XAI\n",
      "machine learning\n",
      "explainable AI\n",
      "Python\n",
      "Mastering Named Entity Recognition (NER) in Data Science\n",
      "Nov 2019\n",
      "Extracting Keywords from Medium Articles Using SpaCy\n",
      "NLP\n",
      "Python\n",
      "machine learning\n",
      "NER\n",
      "language models\n",
      "Women in Healthcare Analytics and Data Science (WiHADS)\n",
      "Oct 2019\n",
      "Leading the Charge in Data Science and AI\n",
      "data science\n",
      "events\n",
      "healthcare\n",
      "networking\n",
      "PhD Thesis\n",
      "Aug 2018\n",
      "The full text of my PhD Thesis - Unsupervised deconvolution of bulk...\n",
      "Machine Learning\n",
      "R\n",
      "Data Science\n",
      "biomedical applications\n",
      "DeconICA\n",
      "May 2018\n",
      "R package for cell-type deconvolution of transcriptomic data\n",
      "Machine Learning\n",
      "R\n",
      "Data Science\n",
      "Deconvolution\n",
      "PhD thesis at Institut Curie\n",
      "Jan 2016\n",
      "dimension reduction of high-dimensional data using unsupervised machine learning\n",
      "Machine learning\n",
      "data visualization\n",
      "R\n",
      "public speaking\n",
      "scientific writing\n",
      "healthcare\n",
      "DeDaL\n",
      "Jun 2014\n",
      "Data-driven network layout\n",
      "Java\n",
      "Networks\n",
      "PCA\n",
      "Data viz\n",
      "Introduction to data visualization [FR]\n",
      "Mar 2015\n",
      "R-plot & ggplot2\n",
      "Teaching\n",
      "R\n",
      "Data viz\n",
      "Outreach\n",
      "Nov 2016\n",
      "four years of workshop \"Certificate in Business Administration\"\n",
      "Tableau\n",
      "Infographic\n",
      "Communication\n",
      "Business Administration\n",
      "From Science to Data Science\n",
      "Jan 2017\n",
      "organised seminar series to accompany transition from academia to industry\n",
      "Machine Learning\n",
      "Careers\n",
      "Data Science\n",
      "Data viz\n",
      "Metro microbiome diversity\n",
      "Apr 2015\n",
      "realized in a frame of start-up Eco-Smart Solutions\n",
      "entrepreneurship\n",
      "DNA manipulation\n",
      "Microbiology\n",
      "Isotonic regression\n",
      "Feb 2015\n",
      "biomarker discovery\n",
      "Biomarkers\n",
      "Machine learning\n",
      "Matematica\n",
      "Teen spirit\n",
      "Nov 2014\n",
      "fighting unpleasant smells with bacteria using synthetic biology weapons\n",
      "Synthetic biology\n",
      "Product design\n",
      "Graphical design\n",
      "Modeling MinA and MinB\n",
      "Jan 2014\n",
      "Simple model of gradient diffusion\n",
      "Matlab\n",
      "Galaxy pipeline for metabolomics\n",
      "Jun 2013\n",
      "bridge from R to Galaxy.org\n",
      "GUI\n",
      "R\n",
      "shell\n",
      "twitter\n",
      "github\n",
      "linkedin-square\n",
      "E-mail\n",
      "© 2016,\n",
      "    2024\n",
      "      Urszula Czerwinska\n",
      "Credits\n",
      "\n",
      "\n",
      "\n",
      "careers page\n",
      "Webpage Title:\n",
      "Thoughts\n",
      "Webpage Contents:\n",
      "Urszula Czerwinska\n",
      "Menu\n",
      "Home\n",
      "About\n",
      "Works\n",
      "Thoughts\n",
      "RSS Feed\n",
      "Thoughts\n",
      "Ideas & Insights\n",
      "Home\n",
      "Thoughts\n",
      "Look at my\n",
      "Medium\n",
      "profile\n",
      "@ulalaparis\n",
      "- for even more great content on ML, AI and Data Scientist life !\n",
      "Featured\n",
      "2024\n",
      "[19 Jun]\n",
      "Dilated Diffusion from DemoFusion\n",
      "5 Ways It's Transforming AI Image Generation\n",
      "[25 Apr]\n",
      "Embracing the Unknown 2/2\n",
      "Exclusive insights and lessons from top AI startup and tech speakers at...\n",
      "[13 Apr]\n",
      "Embracing the Unknown 1/2\n",
      "Applying to AI Startup School — Reflections on Entrepreneurship, Risk, and Personal Growth\n",
      "[03 Feb]\n",
      "The Mamba Effect\n",
      "Mamba models gaining ground in artificial intelligence research.\n",
      "[03 Jan]\n",
      "From PCA to SSL - A personal odyssey in Data Science\n",
      "Tracing the evolution - My journey through the changing landscape of machine...\n",
      "2023\n",
      "[19 Dec]\n",
      "AI Foundation Models\n",
      "A new vision for E-commerce\n",
      "2019\n",
      "[19 Jan]\n",
      "Language gap between academia and business\n",
      "Transitioning from Academia to Industry, a Data Scientist Perspective\n",
      "2017\n",
      "[28 Aug]\n",
      "Big Dive\n",
      "Big Data and data visualization kick off bootcamp for aspiring data scientists...\n",
      "[30 Jan]\n",
      "Hi, I am Computational Biologist\n",
      "would you hire me?\n",
      "2016\n",
      "[11 Nov]\n",
      "Data and the Future of Healthcare\n",
      "Interview with Phil Bourne\n",
      "[27 Oct]\n",
      "Data Innovation\n",
      "Data Science at Hello Tomorrow Global Summit\n",
      "[13 Sep]\n",
      "Intro and retrospective on Computational Biology & Data\n",
      "Live blogging from conference\n",
      "[19 Jul]\n",
      "Career transition - from academia to industry\n",
      "Live blogging from conference\n",
      "[08 Jul]\n",
      "Student Council Symposium at Orlando\n",
      "Live blogging from computational biology conference\n",
      "[01 Jul]\n",
      "Learning business at Sorbonne\n",
      "Certificate of Business and Administration for Ph. D. students at Sorbonne\n",
      "[29 Jun]\n",
      "Blogging at ISMB2016 Florida for Plos Computational Biology\n",
      "Live blogging from conference\n",
      "twitter\n",
      "github\n",
      "linkedin-square\n",
      "E-mail\n",
      "© 2016,\n",
      "    2024\n",
      "      Urszula Czerwinska\n",
      "Credits\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "9b863a55-f86c-4e3f-8a79-94e24c1a8cf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:24:34.428767Z",
     "start_time": "2025-01-27T08:24:34.421101Z"
    }
   },
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a peronal blog website \\\n",
    "and creates a short brochure about the profile for prospective customers, investors and recruiters. Respond in markdown.\\\n",
    "Include details of profile qualities, careers if you have the information.\"\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "# system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "# and creates a short humorous, entertaining, jokey brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\"\n"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "6ab83d92-d36b-4ce0-8bcc-5bb4c2f8ff23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:24:45.829756Z",
     "start_time": "2025-01-27T08:24:45.824800Z"
    }
   },
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a person called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "cd909e0b-1312-4ce2-a553-821e795d7572",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:25:10.087208Z",
     "start_time": "2025-01-27T08:25:04.665066Z"
    }
   },
   "source": "get_brochure_user_prompt(\"Urszula Czerwinska\", \"https://urszulaczerwinska.github.io/\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://urszulaczerwinska.github.io/about/'}, {'type': 'works page', 'url': 'https://urszulaczerwinska.github.io/works/'}, {'type': 'thoughts page', 'url': 'https://urszulaczerwinska.github.io/thoughts/'}, {'type': 'twitter', 'url': 'https://twitter.com/ulalaparis'}, {'type': 'github', 'url': 'https://github.com/urszulaczerwinska'}, {'type': 'linkedin', 'url': 'https://linkedin.com/in/urszulaczerwinska'}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"You are looking at a person called: Urszula Czerwinska\\nHere are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\nLanding page:\\nWebpage Title:\\nUrszula Czerwinska | Python, TensorFlow Expert | Data Scientist & Deep Learning Engineer\\nWebpage Contents:\\nUrszula Czerwinska\\nMenu\\nHome\\nAbout\\nWorks\\nThoughts\\nRSS Feed\\nUrszula Czerwinska\\nScience → Data Science\\nContinue\\nWelcome to My Data Science Journey\\nWelcome to my personal blog, where I documented my transition from a PhD in Computational Biology to a thriving career in Data Science. Here, you’ll find insights on where to learn data science, how data science and machine learning, artificial intelligence are revolutionizing various fields, and explore whether data science can be self-taught, are data science bootcamps or courses worth it. Discover why data science is important in today’s world.\\ntwitter\\ngithub\\nlinkedin-square\\nThoughts\\nWelcome to my Thoughts page, where I explore the dynamic intersections of my professional journey. Here, I share reflections on attending conferences, maintaining work-life balance, and the challenging transition from academia to industry. You’ll also find my evaluations of Data Science bootcamps and courses, along with insights into the latest state-of-the-art (SOTA) deep learning trends. Drawing from my PhD experience and ongoing career, these articles offer a candid look at the evolving landscape of data science and the realities of working at the cutting edge of technology.\\nWorks\\nWelcome to my Works portfolio. Here, you'll find my PhD research on cancer computational biology, focusing on dimension reduction with ICA, alongside my NLP and model explainability (SHAP) projects from my consulting experience. Also featured are the NLP (NER), Deep Learning projects I completed at the French Supreme Court, and my recent work in Computer Vision and Generative AI. This portfolio reflects my ability to solve complex challenges and drive innovation across diverse fields and application of Deep Learning algorithms in industry.\\nRecent posts\\nExplore my latest highlights, featuring standout projects and insights on the transition from academia to industry & life of Data Scientist / Deep learning engineer. Whether it’s hands-on work or reflections from the field, these featured posts capture the key moments of my data science journey.\\nDeep Dive in PaddleOCR inference\\nDiscover the complexities of using PaddleOCR as a Text in Image service and how the Cognition...\\nNamed Entity Recognition Tool by Cour de Cassation\\nDescription of pseudonymisation for Open Data of French Supreme Court decisions\\nPush the limits of machine learning explainability\\nan ultimate guide to SHAP library\\nMastering Named Entity Recognition (NER) in Data Science\\nExtracting Keywords from Medium Articles Using SpaCy\\nThanks for visiting, dear Data Science Lover !\\nFeel free to get in touch and talk about how deep learning can help your business or solve your problem. Let's connect!\\ntwitter\\ngithub\\nlinkedin-square\\nE-mail\\n© 2016,\\n    2024\\n      Urszula Czerwinska\\nCredits\\n\\n\\n\\nabout page\\nWebpage Title:\\nAbout\\nWebpage Contents:\\nUrszula Czerwinska\\nMenu\\nHome\\nAbout\\nWorks\\nThoughts\\nRSS Feed\\nAbout\\nExpert Deep Learning Engineer in Paris | AI, Data Science, and Industry Solutions\\nHome\\nAbout\\nUrszula Czerwinska\\nSenior Deep Learning engineer, Data Scientist, PhD\\nurszula.czerwinska@cri-paris.org\\n|\\nurszulaczerwinska\\n|\\nulalaparis\\n|\\nUrszula Czerwinska\\n          |\\nUlaLaParis\\nDownload CV\\nShort Bio\\nBorn in Poland and having gained diverse educational experiences\\n        across France and Singapore,\\n        I now proudly call Paris home. My journey, rooted in\\nbio-mathematics\\n,\\n        culminating in a\\nPh.D.\\n,\\n        has equipped me with profound expertise in\\ncomplex\\n          systems\\n,\\nstatistics\\n, and\\nprogramming\\n,\\n        particularly in\\nPython\\nand\\nR\\n. These interdisciplinary\\n        experiences\\n        have sharpened my ability to excel in bridging the gap between\\n        theoretical knowledge\\n        and practical application, specially in the realms of\\ndeep\\n          learning\\nand\\ndata science\\n.\\nAs a\\nSenior Deep Learning Engineer - Data Scientist\\nat\\nAdevinta\\nin Paris, my current\\n        focus is\\n        on spearheading advancements in\\ncomputer vision\\nand\\nmultimodal AI models\\n. I lead the strategic development\\n        of\\nfoundation models\\nthat drive product innovation and\\n        enhance\\ne-commerce solutions\\n. My work leverages\\n        cutting-edge technologies like\\nPyTorch\\n,\\nTensorFlow\\n, and\\nKubernetes\\n, where I guide my team to deliver\\n        exceptional results.\\n        Notably, I’ve improved\\nscene-text extraction\\ncapabilities by\\n33%\\nand optimized multi-class classification models to\\n        increase\\n        accuracy by\\n45%\\n.\\nMy role at Adevinta also encompasses leadership beyond technical\\n        accomplishments.\\n        As the head of the\\nAdevinta ML Guild\\n, I facilitate paper reading sessions\\n        and am actively in\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "e44de579-4a1a-4e6a-a510-20ea3e4b8d46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:25:13.957358Z",
     "start_time": "2025-01-27T08:25:13.954530Z"
    }
   },
   "source": [
    "def create_brochure(company_name, url):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "e093444a-9407-42ae-924a-145730591a39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:25:44.248742Z",
     "start_time": "2025-01-27T08:25:28.918749Z"
    }
   },
   "source": "create_brochure(\"Urszula Czerwinska\", \"https://urszulaczerwinska.github.io/\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://urszulaczerwinska.github.io/about/'}, {'type': 'works page', 'url': 'https://urszulaczerwinska.github.io/works/'}, {'type': 'twitter', 'url': 'https://twitter.com/ulalaparis'}, {'type': 'github', 'url': 'https://github.com/urszulaczerwinska'}, {'type': 'linkedin', 'url': 'https://linkedin.com/in/urszulaczerwinska'}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```markdown\n# Brochure: Urszula Czerwinska - Data Scientist & Deep Learning Engineer\n\n## Profile Overview\nUrszula Czerwinska is an accomplished Senior Deep Learning Engineer and Data Scientist based in Paris, with a unique background transitioning from a PhD in Computational Biology to becoming a key innovator in the field of Artificial Intelligence and Data Science. \n\n## Contact Information\n- **Email:** urszula.czerwinska@cri-paris.org\n- **Twitter:** [@urszulaczerwinska](https://twitter.com/urszulaczerwinska)\n- **GitHub:** [UlaLaParis](https://github.com/UlaLaParis)\n- **LinkedIn:** [Urszula Czerwinska](https://linkedin.com/in/urszulaczerwinska)\n\n## Career Highlights\n- **Current Position:** Senior Deep Learning Engineer, Data Scientist at Adevinta, Paris\n- **Key Skills:** \n  - Expertise in Python, R, TensorFlow, and PyTorch\n  - Strong foundation in complex systems, machine learning, and deep learning\n  - Specialization in computer vision and multimodal AI models\n- **Achievements:**\n  - Led the enhancement of scene-text extraction capabilities by 33%\n  - Optimized multi-class classification models to increase accuracy by 45%\n  - Head of Adevinta ML Guild, fostering a culture of continuous learning and innovation\n\n## Academic Background\n- PhD in Computational Biology, focusing on cancer and data analysis\n- Extensive education across France and Singapore, enriching her interdisciplinary approach to problem-solving\n\n## Areas of Expertise\n- **Data Science & Machine Learning:** Insights on how data science is evolving and its importance in today's world including discussions on self-taught methods, bootcamps, and industry trends.\n- **Deep Learning:** Specializing in projects involving Natural Language Processing (NLP), model explainability, and recent advancements in Computer Vision and Generative AI.\n- **Industry Solutions:** Provides consulting services in deep learning technologies, helping businesses innovate and solve complex problems.\n\n## Portfolio & Works\nUrszula has documented her works showcasing:\n- Research in cancer computational biology\n- Hands-on projects at the French Supreme Court \n- Projects focused on NLP (Named Entity Recognition) and modern machine learning algorithms\n\n### Notable Projects\n- **PaddleOCR Inference:** An exploration of using PaddleOCR as a Text in Image service.\n- **Named Entity Recognition Tool:** Developed for the Open Data of the French Supreme Court.\n- **SHAP Library Mastery:** A comprehensive guide on push the limits of machine learning explainability.\n\n## Thoughts & Insights\nOn her blog, Urszula shares reflections from her career journey, evaluations of educational opportunities in data science, and insights into the latest SOTA deep learning trends.\n\n## Connecting with Urszula\nUrszula invites businesses and individuals interested in leveraging deep learning technologies to connect and explore collaboration possibilities. \n\n> \"Let’s talk about how deep learning can help your business or solve your problem.\" \n```\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "61eaaab7-0b47-4b29-82d4-75d474ad8d18",
   "metadata": {},
   "source": [
    "## Finally - a minor improvement\n",
    "\n",
    "With a small adjustment, we can change this so that the results stream back from OpenAI,\n",
    "with the familiar typewriter animation"
   ]
  },
  {
   "cell_type": "code",
   "id": "51db0e49-f261-4137-aabe-92dd601f7725",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:27:07.576255Z",
     "start_time": "2025-01-27T08:27:07.568373Z"
    }
   },
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "56bf0ae3-ee9d-4a72-9cd6-edcac67ceb6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:27:41.349767Z",
     "start_time": "2025-01-27T08:27:25.149691Z"
    }
   },
   "source": "stream_brochure(\"Urszula Czerwinska\", \"https://urszulaczerwinska.github.io/\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://urszulaczerwinska.github.io/about/'}, {'type': 'works page', 'url': 'https://urszulaczerwinska.github.io/works/'}, {'type': 'GitHub profile', 'url': 'https://github.com/urszulaczerwinska'}, {'type': 'LinkedIn profile', 'url': 'https://linkedin.com/in/urszulaczerwinska'}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "# Urszula Czerwinska - Data Scientist & Deep Learning Engineer\n\n---\n\n## Introduction\n\nUrszula Czerwinska is a seasoned **Data Scientist** and **Deep Learning Engineer** with a profound background in **Computational Biology**. Based in Paris, her work integrates the complexities of data science and cutting-edge deep learning techniques to foster innovation in various industries, particularly e-commerce and AI solutions.\n\n---\n\n## Professional Profile\n\n### Expertise:\n- **Data Science & Machine Learning**: Specializes in translating complex datasets into actionable insights.\n- **Deep Learning**: Skilled in frameworks such as **TensorFlow** and **PyTorch**.\n- **Computer Vision**: Extensive work on scene-text extraction and multimodal AI models.\n- **Natural Language Processing (NLP)**: Experience in named entity recognition and model explainability (SHAP).\n\n### Education:\n- **Ph.D. in Computational Biology** from a reputable institution. Focus on cancer research and computational methodologies.\n\n### Skills:\n- Proficient in programming with **Python** and **R**.\n- Expertise in statistics, complex systems, and model optimization.\n- Strong leadership capabilities, fostering collaboration among teams.\n\n---\n\n## Career Highlights\n\nCurrently serving as a **Senior Deep Learning Engineer** at **Adevinta**, Urszula has successfully:\n- Spearheaded advancements in **scene-text extraction**, boosting capabilities by **33%**.\n- Optimized **multi-class classification models**, increasing accuracy by **45%**.\n- Led the **Adevinta ML Guild**, promoting knowledge sharing and collaborative learning.\n\n---\n\n## Notable Projects\n- **Cancer Computational Biology**: Pioneered research focusing on dimension reduction techniques.\n- **NLP Projects at French Supreme Court**: Developed tools for pseudonymization of Open Data in legal decisions.\n- **Computer Vision & Generative AI**: Engaged in innovative projects that apply deep learning solutions to real-world challenges.\n\n---\n\n## Community Engagement\nUrszula actively contributes to the data science community by sharing insights through her blog. She discusses:\n- The transition from academia to industry.\n- Evaluations of data science bootcamps and courses.\n- Current trends in deep learning and AI.\n\n---\n\n## Get in Touch\nCurious about how Urszula can help your business with deep learning solutions, or want to discuss the evolving landscape of data science? You can connect with her:\n\n- **Email**: [urszula.czerwinska@cri-paris.org](mailto:urszula.czerwinska@cri-paris.org)\n- **LinkedIn**: [Urszula Czerwinska](https://www.linkedin.com/in/urszulaczerwinska/)\n- **GitHub**: [ulalaparis](https://github.com/ulalaparis)\n- **Twitter**: [@UrszulaC](https://twitter.com/UrszulaC)\n\n---\n\n## Conclusion\nUrszula Czerwinska represents the intersection of academia and industry, leveraging her extensive knowledge to drive innovation in data science and deep learning. With a passion for problem-solving and a commitment to advancing technology, she stands as a remarkable asset for prospective employers, clients, and partners alike.\n\n--- \n\nThank you for considering Urszula Czerwinska as a potential collaborator or expert consultant in your data science needs!"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb3f8d8-a3eb-41c8-b1aa-9f60686a653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try changing the system prompt to the humorous version when you make the Brochure for Hugging Face:\n",
    "\n",
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27bf9e0-665f-4645-b66b-9725e2a959b5",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business applications</h2>\n",
    "            <span style=\"color:#181;\">In this exercise we extended the Day 1 code to make multiple LLM calls, and generate a document.\n",
    "\n",
    "This is perhaps the first example of Agentic AI design patterns, as we combined multiple calls to LLMs. This will feature more in Week 2, and then we will return to Agentic AI in a big way in Week 8 when we build a fully autonomous Agent solution.\n",
    "\n",
    "Generating content in this way is one of the very most common Use Cases. As with summarization, this can be applied to any business vertical. Write marketing content, generate a product tutorial from a spec, create personalized email content, and so much more. Explore how you can apply content generation to your business, and try making yourself a proof-of-concept prototype.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2454b-8ef8-4b5c-b928-053a15e0d553",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you move to Week 2 (which is tons of fun)</h2>\n",
    "            <span style=\"color:#900;\">Please see the week1 EXERCISE notebook for your challenge for the end of week 1. This will give you some essential practice working with Frontier APIs, and prepare you well for Week 2.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b64f0f-7d33-4493-985a-033d06e8db08",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">A reminder on 2 useful resources</h2>\n",
    "            <span style=\"color:#f71;\">1. The resources for the course are available <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">here.</a><br/>\n",
    "            2. I'm on LinkedIn <a href=\"https://www.linkedin.com/in/eddonner/\">here</a> and I love connecting with people taking the course!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48e42e-fa7a-495f-a5d4-26bfc24d60b6",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../thankyou.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#090;\">Finally! I have a special request for you</h2>\n",
    "            <span style=\"color:#090;\">\n",
    "                My editor tells me that it makes a MASSIVE difference when students rate this course on Udemy - it's one of the main ways that Udemy decides whether to show it to others. If you're able to take a minute to rate this, I'd be so very grateful! And regardless - always please reach out to me at ed@edwarddonner.com if I can help at any point.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d3e1a1-ba54-4907-97c5-30f89a24775b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
